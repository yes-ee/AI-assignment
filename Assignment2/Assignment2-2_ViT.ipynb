{"cells":[{"cell_type":"markdown","metadata":{"id":"cmKpbnG0UXZu"},"source":["# 2150188401(2) Artificial Intelligence Assignment #2-2<br> Training Vision Transformers (PyTorch)"]},{"cell_type":"markdown","metadata":{"id":"uDoebvl5UXZz"},"source":["Copyright (C) Computer Science & Engineering, Soongsil University. This material is for educational uses only. Some contents are based on the material provided by other paper/book authors and may be copyrighted by them. Written by Haneul Pyeon, September 2024."]},{"cell_type":"markdown","metadata":{"id":"ixBCEom7UXZ0"},"source":["**For understanding of this work, please carefully look at given PDF file.**\n","\n","Now, you're going to leave behind your implementations and instead migrate to one of popular deep learning frameworks, **PyTorch**. <br>\n","In this notebook, you will learn to understand and build the basic components of Vision Tranformer(ViT). Then, you will try to classify images in the FashionMNIST datatset and explore the effects of different components of ViTs.\n","<br>\n","There are **2 sections**, and in each section, you need to follow the instructions to complete the skeleton codes and explain them.\n","\n","**Note**: certain details are missing or ambiguous on purpose, in order to test your knowledge on the related materials. However, if you really feel that something essential is missing and cannot proceed to the next step, then contact the teaching staff with clear description of your problem.\n","\n","### Submitting your work:\n","<font color=red>**DO NOT clear the final outputs**</font> so that TAs can grade both your code and results.\n","\n","### Some helpful tutorials and references for assignment #2-2:\n","- [1] Pytorch official documentation [[link]](https://pytorch.org/docs/stable/index.html).\n","- [2] Stanford CS231n lectures [[link]](http://cs231n.stanford.edu/).\n","- [3] Alexey Dosovitskiy et al., \"An Image is Worth 16 x 16 Words: Transformers for Image Recognition at Scale\", ICLR 2021 [[pdf]](https://arxiv.org/pdf/2010.11929.pdf)."]},{"cell_type":"markdown","metadata":{"id":"tDRHFwOtUXZ0"},"source":["## 1. Building Vision Transformer\n","Here, you will build the basic components of Vision Transformer(ViT). <br>\n","\n","![Vision Transformer](imgs/ViT.png)\n","\n","Using the explanation and code provided as guidance, <br>\n","Define each component of ViT. <br>\n","\n","\n","#### ViT architecture:\n","* ViT model consists with input patch embedding, positional embeddings, transformer encoder, etc.\n","* Patch embedding\n","* Positional embeddings\n","* Transformer encoder with\n","    * Attention module\n","    * MLP module"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"suPU1H71UXZ1","executionInfo":{"status":"ok","timestamp":1730454343359,"user_tz":-540,"elapsed":753,"user":{"displayName":"A","userId":"15796530327741791199"}}},"outputs":[],"source":["import torch\n","import torch.nn as nn"]},{"cell_type":"markdown","metadata":{"id":"GWRDmxneUXZ2"},"source":["##### Patch Embed\n","\n","**Initialization**: When you create an instance of the PatchEmbedding class, you specify the image_size, patch_size, and in_channels. image_size is the height and width of the input image, patch_size is the size of each patch, and in_channels is the number of input image channels (e.g., 3 for RGB images).\n","\n","**Convolutional Projection**: Inside the PatchEmbedding class, a 2D convolutional layer (nn.Conv2d) is used to perform a patch-based projection. This convolutional layer has a kernel size of patch_size, which defines the size of each patch, and a stride of patch_size, which ensures that patches do not overlap. The convolutional layer effectively extracts image patches.\n","\n","**Reshaping**: After the convolutional projection, the output tensor is reshaped using view. It is transformed from a 4D tensor with dimensions (batch_size, in_channels, H, W) to a 3D tensor with dimensions (batch_size, num_patches, patch_dim). num_patches is the total number of non-overlapping patches in the image, and patch_dim is the number of output channels from the convolutional layer."]},{"cell_type":"code","execution_count":7,"metadata":{"id":"3iRn_MviUXZ2","executionInfo":{"status":"ok","timestamp":1730454343895,"user_tz":-540,"elapsed":8,"user":{"displayName":"A","userId":"15796530327741791199"}}},"outputs":[],"source":["class PatchEmbed(nn.Module):\n","    \"\"\" Image to Patch Embedding\n","    \"\"\"\n","\n","    def __init__(self, img_size=224, patch_size=16, in_chans=3, embed_dim=768):\n","        super().__init__()\n","        num_patches = (img_size // patch_size) * (img_size // patch_size)\n","        self.img_size = img_size\n","        self.patch_size = patch_size\n","        self.num_patches = num_patches\n","\n","        ##############################################################################\n","        #                           IMPLEMENT YOUR CODE                              #\n","        ##############################################################################\n","\n","        # 2D convolution layer\n","        self.proj = nn.Conv2d(in_chans, embed_dim, kernel_size=patch_size, stride=patch_size)\n","\n","        ##############################################################################\n","        #                              END YOUR CODE                                 #\n","        ##############################################################################\n","    def forward(self, x):\n","        ##############################################################################\n","        #                           IMPLEMENT YOUR CODE                              #\n","        ##############################################################################\n","\n","        B, C, H, W = x.shape\n","        x = self.proj(x).flatten(2).transpose(1, 2)\n","\n","        ##############################################################################\n","        #                              END YOUR CODE                                 #\n","        ##############################################################################\n","        return x # output dimension must be: (batch size, number of patches, embed_dim)"]},{"cell_type":"markdown","metadata":{"id":"6oyNaejWUXZ3"},"source":["##### Attention\n","\n","**Initialization**\n","* dim: The input dimension of the sequence. This is the dimensionality of the queries, keys, and values.\n","* num_heads: The number of attention heads to use. Multi-head attention allows the model to focus on different parts of the input simultaneously.\n","\n","**Linear Projections (qkv and proj)**: The qkv linear layer takes the input sequence and projects it into three parts: queries (q), keys (k), and values (v). The output of this layer has a shape of (batch_size, sequence_length, 3 * dim).\n","\n","**Forward Pass (forward method)**: In the forward pass, the input tensor x is processed through the attention mechanism. Here's what happens:<br>\n","* The linear projection qkv is applied to x, producing a tensor of shape (batch_size, sequence_length, 3 * dim).|\n","* This tensor is reshaped to have dimensions (batch_size, sequence_length, 3, num_heads, head_dim). The permute operation rearranges the dimensions to (3, batch_size, num_heads, sequence_length, head_dim), making it suitable for multi-head attention.\n","* The three parts, q, k, and v, are extracted from the reshaped tensor.\n","* The attention scores are computed by taking the dot product of queries q and keys k. The result is scaled by self.scale.\n","* The attention scores are passed through a softmax activation along the last dimension (sequence_length), producing attention weights.\n","* The weighted sum of values v is computed using the attention weights.\n","* The result is transposed and reshaped to its original shape, and then passed through the proj linear layer.\n","* The final output is returned."]},{"cell_type":"code","execution_count":8,"metadata":{"id":"Wqte44SkUXZ3","executionInfo":{"status":"ok","timestamp":1730454343895,"user_tz":-540,"elapsed":7,"user":{"displayName":"A","userId":"15796530327741791199"}}},"outputs":[],"source":["class Attention(nn.Module):\n","    def __init__(self, dim, num_heads=8):\n","        super().__init__()\n","        self.num_heads = num_heads\n","        head_dim = dim // num_heads\n","        self.scale = head_dim ** -0.5\n","\n","        self.qkv = nn.Linear(dim, dim * 3)\n","        self.proj = nn.Linear(dim, dim)\n","\n","    def forward(self, x):\n","        B, N, C = x.shape\n","        ##############################################################################\n","        #                           IMPLEMENT YOUR CODE                              #\n","        ##############################################################################\n","\n","        qkv = self.qkv(x).reshape(B, N, 3, self.num_heads, C // self.num_heads).permute(2, 0, 3, 1, 4)\n","        q, k, v = qkv[0], qkv[1], qkv[2]\n","\n","        attn = (q @ k.transpose(-2, -1)) * self.scale\n","        attn = attn.softmax(dim=-1)\n","\n","        ##############################################################################\n","        #                              END YOUR CODE                                 #\n","        ##############################################################################\n","\n","        x = (attn @ v).transpose(1, 2).reshape(B, N, C)\n","        x = self.proj(x)\n","\n","        return x # output dimension must be: (batch size, number of patches, embed_dim)"]},{"cell_type":"markdown","metadata":{"id":"JPr_KU5gUXZ4"},"source":["##### MLP\n","\n","The MLP module must consist of three layers:\n","* fully conncted layer 1\n","* activation layer\n","* fully conncted layer 2"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"KN5Lg_O8UXZ4","executionInfo":{"status":"ok","timestamp":1730454343895,"user_tz":-540,"elapsed":7,"user":{"displayName":"A","userId":"15796530327741791199"}}},"outputs":[],"source":["class Mlp(nn.Module):\n","    def __init__(self, in_features, hidden_features=None, out_features=None, act_layer=nn.GELU):\n","        super().__init__()\n","        out_features = out_features or in_features\n","        hidden_features = hidden_features or in_features\n","\n","        ##############################################################################\n","        #                           IMPLEMENT YOUR CODE                              #\n","        ##############################################################################\n","\n","        # Mlp layer\n","        self.fc1 = nn.Linear(in_features, hidden_features)\n","        self.act = act_layer()\n","        self.fc2 = nn.Linear(hidden_features, out_features)\n","\n","\n","        ##############################################################################\n","        #                              END YOUR CODE                                 #\n","        ##############################################################################\n","\n","    def forward(self, x):\n","        ##############################################################################\n","        #                           IMPLEMENT YOUR CODE                              #\n","        ##############################################################################\n","\n","        x = self.fc1(x)\n","        x = self.act(x)\n","        x = self.fc2(x)\n","\n","        ##############################################################################\n","        #                              END YOUR CODE                                 #\n","        ##############################################################################\n","        return x # output dimension must be: (batch size, number of patches, out_features)"]},{"cell_type":"markdown","metadata":{"id":"Ze_gwuzeUXZ4"},"source":["##### Transformer Block\n","The transformer block contains the attention module and MLP module which have residual connections.\n","Refer to the following image and build the forward pass.\n","\n","![Transformer Block](imgs/TransformerBlock.png)"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"bQ7rxC8_UXZ4","executionInfo":{"status":"ok","timestamp":1730454343895,"user_tz":-540,"elapsed":7,"user":{"displayName":"A","userId":"15796530327741791199"}}},"outputs":[],"source":["class Block(nn.Module):\n","    def __init__(self, dim, num_heads, mlp_ratio=4., act_layer=nn.GELU, norm_layer=nn.LayerNorm):\n","        super().__init__()\n","        self.norm1 = norm_layer(dim)\n","        self.attn = Attention(dim, num_heads=num_heads)\n","        self.norm2 = norm_layer(dim)\n","        mlp_hidden_dim = int(dim * mlp_ratio)\n","        self.mlp = Mlp(in_features=dim, hidden_features=mlp_hidden_dim,\n","                       act_layer=act_layer)\n","\n","    def forward(self, x):\n","        ##############################################################################\n","        #                           IMPLEMENT YOUR CODE                              #\n","        ##############################################################################\n","\n","        x = x + self.attn(self.norm1(x))\n","        x = x + self.mlp(self.norm2(x))\n","\n","        ##############################################################################\n","        #                              END YOUR CODE                                 #\n","        ##############################################################################\n","        return x\n"]},{"cell_type":"markdown","metadata":{"id":"mWL8C6d6UXZ4"},"source":["##### Vision Transformer\n","\n","Using all the components that you built above, **complete** the vision transformer class."]},{"cell_type":"markdown","metadata":{"id":"iSroUEH_UXZ5"},"source":["### torch.cat\n","\n","Concatenates the given sequence of tensors along the specified dimension. All tensors must either have the same shape (except in the concatenating dimension) or be a 1-D empty tensor with size (0,).\n","\n","`torch.cat()` can be seen as an inverse operation for `torch.split()` and `torch.chunk()`.\n","\n","`torch.cat()` can be best understood via examples."]},{"cell_type":"markdown","metadata":{"id":"hbK1TmLqUXZ5"},"source":["#### Parameters\n","\n","- **tensors** (sequence of Tensors): any Python sequence of tensors of the same type. Non-empty tensors provided must have the same shape, except in the concatenating dimension.\n","\n","- **dim** (int, optional): the dimension over which the tensors are concatenated.\n","\n","#### Keyword Arguments\n","\n","- **out** (Tensor, optional): the output tensor."]},{"cell_type":"code","execution_count":11,"metadata":{"id":"6wtE-4cVUXZ5","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1730454343895,"user_tz":-540,"elapsed":6,"user":{"displayName":"A","userId":"15796530327741791199"}},"outputId":"9058ad5d-1fda-4351-cc9e-c2a88dab1b81"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[-0.0181, -0.8599, -0.9947],\n","        [-1.4668,  0.4443,  0.0269]])"]},"metadata":{},"execution_count":11}],"source":["# example\n","x = torch.randn(2, 3)\n","x"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"sb5M-9Z_UXZ5","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1730454343895,"user_tz":-540,"elapsed":5,"user":{"displayName":"A","userId":"15796530327741791199"}},"outputId":"aea5d443-3c70-4b56-81c5-b4c1325b7441"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[-0.0181, -0.8599, -0.9947],\n","        [-1.4668,  0.4443,  0.0269],\n","        [-0.0181, -0.8599, -0.9947],\n","        [-1.4668,  0.4443,  0.0269],\n","        [-0.0181, -0.8599, -0.9947],\n","        [-1.4668,  0.4443,  0.0269]])"]},"metadata":{},"execution_count":12}],"source":["exam1 = torch.cat((x, x, x), 0)\n","exam1"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"D7hofP5BUXZ5","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1730454343895,"user_tz":-540,"elapsed":4,"user":{"displayName":"A","userId":"15796530327741791199"}},"outputId":"a8fbb507-274a-4dbb-a3e4-385a2e88fa96"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[-0.0181, -0.8599, -0.9947, -0.0181, -0.8599, -0.9947, -0.0181, -0.8599,\n","         -0.9947],\n","        [-1.4668,  0.4443,  0.0269, -1.4668,  0.4443,  0.0269, -1.4668,  0.4443,\n","          0.0269]])"]},"metadata":{},"execution_count":13}],"source":["exam2 = torch.cat((x, x, x), 1)\n","exam2"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"LeRBWaUDUXZ5","executionInfo":{"status":"ok","timestamp":1730454343896,"user_tz":-540,"elapsed":4,"user":{"displayName":"A","userId":"15796530327741791199"}}},"outputs":[],"source":["class VisionTransformer(nn.Module):\n","    \"\"\" Vision Transformer \"\"\"\n","\n","    def __init__(self, img_size=28, patch_size=4, in_chans=1, num_classes=10, embed_dim=768, depth=12,\n","                 num_heads=12, mlp_ratio=4., norm_layer=nn.LayerNorm, ):\n","        super().__init__()\n","        self.num_features = self.embed_dim = embed_dim\n","        self.num_heads = num_heads\n","        self.depth = depth\n","\n","        self.patch_embed = PatchEmbed(\n","            img_size=img_size, patch_size=patch_size, in_chans=in_chans, embed_dim=embed_dim)\n","        num_patches = self.patch_embed.num_patches\n","\n","        self.cls_token = nn.Parameter(torch.zeros(1, 1, embed_dim))\n","        ##############################################################################\n","        #                           IMPLEMENT YOUR CODE                              #\n","        ##############################################################################\n","        # similarly to cls_token, define a learnable positional embedding that matches the patchified input token size.\n","        self.pos_embed = nn.Parameter(torch.zeros(1, num_patches + 1, embed_dim))\n","\n","        ##############################################################################\n","        #                              END YOUR CODE                                 #\n","        ##############################################################################\n","\n","        self.blocks = nn.ModuleList([\n","            Block(\n","                dim=embed_dim, num_heads=num_heads, mlp_ratio=mlp_ratio,  norm_layer=norm_layer)\n","            for i in range(depth)])\n","        self.norm = norm_layer(embed_dim)\n","\n","        # Classifier head\n","        self.head = nn.Linear(\n","            embed_dim, num_classes) if num_classes > 0 else nn.Identity()\n","\n","    def forward(self, x):\n","        ##############################################################################\n","        #                           IMPLEMENT YOUR CODE                              #\n","        ##############################################################################\n","        B = x.shape[0]\n","\n","        # Patch Embedding\n","        x = self.patch_embed(x)\n","\n","        # Concatenate class tokens to patch embedding\n","        cls_tokens = self.cls_token.expand(B, -1, -1)\n","        x = torch.cat((cls_tokens, x), dim=1)\n","\n","        # Add positional embedding to patches\n","        x = x + self.pos_embed\n","\n","        # Forward through encoder blocks\n","        for blk in self.blocks:\n","            x = blk(x)\n","\n","        # Normalize the output\n","        x = self.norm(x)\n","\n","        # Use class token for classification\n","        cls_token_output = x[:, 0]\n","\n","        # Classifier head\n","        x = self.head(cls_token_output)\n","\n","        ##############################################################################\n","        #                              END YOUR CODE                                 #\n","        ##############################################################################\n","        return x"]},{"cell_type":"markdown","metadata":{"id":"WBZ_3fcMUXZ5"},"source":["## 2. Training a small ViT model on FashionMNIST dataset.\n","\n","Define and Train a vision transformer on FashionMNIST dataset. **(You must reach above 85% for full points.)** <br>\n","Train with at least 5 different hyperparameter settings varying the following ViT hyperparameters.\n","Report the setting for the best performance.\n","\n","#### ViT hyperparameters:\n","* patch_size\n","* embed_dim\n","* depth\n","* num_heads\n","* mlp_ratio\n","* etc.\n"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"fpbpio7hUXZ6","executionInfo":{"status":"ok","timestamp":1730454348191,"user_tz":-540,"elapsed":4299,"user":{"displayName":"A","userId":"15796530327741791199"}}},"outputs":[],"source":["import numpy as np\n","\n","from tqdm import tqdm, trange\n","\n","import torch\n","import torch.nn as nn\n","from torch.optim import Adam\n","from torch.nn import CrossEntropyLoss\n","from torch.utils.data import DataLoader\n","\n","from torchvision.transforms import ToTensor\n","from torchvision.datasets.mnist import FashionMNIST"]},{"cell_type":"code","execution_count":23,"metadata":{"id":"72ratTTLUXZ6","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1730455489309,"user_tz":-540,"elapsed":82423,"user":{"displayName":"A","userId":"15796530327741791199"}},"outputId":"ba7f0426-592b-4b73-b094-90592ad902f3"},"outputs":[{"output_type":"stream","name":"stdout","text":["Using device:  cuda (Tesla T4)\n"]},{"output_type":"stream","name":"stderr","text":["Training:   0%|          | 0/5 [00:00<?, ?it/s]\n","Epoch 1 in training:   0%|          | 0/469 [00:00<?, ?it/s]\u001b[A\n","Epoch 1 in training:   1%|          | 3/469 [00:00<00:16, 28.72it/s]\u001b[A\n","Epoch 1 in training:   1%|▏         | 6/469 [00:00<00:16, 28.42it/s]\u001b[A\n","Epoch 1 in training:   2%|▏         | 10/469 [00:00<00:15, 29.69it/s]\u001b[A\n","Epoch 1 in training:   3%|▎         | 14/469 [00:00<00:14, 31.40it/s]\u001b[A\n","Epoch 1 in training:   4%|▍         | 18/469 [00:00<00:14, 32.01it/s]\u001b[A\n","Epoch 1 in training:   5%|▍         | 22/469 [00:00<00:13, 32.50it/s]\u001b[A\n","Epoch 1 in training:   6%|▌         | 26/469 [00:00<00:13, 33.08it/s]\u001b[A\n","Epoch 1 in training:   6%|▋         | 30/469 [00:00<00:13, 33.42it/s]\u001b[A\n","Epoch 1 in training:   7%|▋         | 34/469 [00:01<00:13, 31.43it/s]\u001b[A\n","Epoch 1 in training:   8%|▊         | 38/469 [00:01<00:14, 30.73it/s]\u001b[A\n","Epoch 1 in training:   9%|▉         | 42/469 [00:01<00:13, 31.49it/s]\u001b[A\n","Epoch 1 in training:  10%|▉         | 46/469 [00:01<00:13, 32.01it/s]\u001b[A\n","Epoch 1 in training:  11%|█         | 50/469 [00:01<00:12, 32.41it/s]\u001b[A\n","Epoch 1 in training:  12%|█▏        | 54/469 [00:01<00:12, 32.89it/s]\u001b[A\n","Epoch 1 in training:  12%|█▏        | 58/469 [00:01<00:12, 33.52it/s]\u001b[A\n","Epoch 1 in training:  13%|█▎        | 62/469 [00:01<00:12, 32.89it/s]\u001b[A\n","Epoch 1 in training:  14%|█▍        | 66/469 [00:02<00:12, 31.30it/s]\u001b[A\n","Epoch 1 in training:  15%|█▍        | 70/469 [00:02<00:13, 30.59it/s]\u001b[A\n","Epoch 1 in training:  16%|█▌        | 74/469 [00:02<00:12, 31.41it/s]\u001b[A\n","Epoch 1 in training:  17%|█▋        | 78/469 [00:02<00:13, 29.65it/s]\u001b[A\n","Epoch 1 in training:  17%|█▋        | 81/469 [00:02<00:13, 27.86it/s]\u001b[A\n","Epoch 1 in training:  18%|█▊        | 84/469 [00:02<00:14, 26.34it/s]\u001b[A\n","Epoch 1 in training:  19%|█▊        | 87/469 [00:02<00:14, 26.03it/s]\u001b[A\n","Epoch 1 in training:  19%|█▉        | 90/469 [00:02<00:14, 25.88it/s]\u001b[A\n","Epoch 1 in training:  20%|█▉        | 93/469 [00:03<00:15, 24.43it/s]\u001b[A\n","Epoch 1 in training:  20%|██        | 96/469 [00:03<00:15, 23.52it/s]\u001b[A\n","Epoch 1 in training:  21%|██        | 99/469 [00:03<00:15, 24.21it/s]\u001b[A\n","Epoch 1 in training:  22%|██▏       | 102/469 [00:03<00:14, 24.89it/s]\u001b[A\n","Epoch 1 in training:  22%|██▏       | 105/469 [00:03<00:14, 24.87it/s]\u001b[A\n","Epoch 1 in training:  23%|██▎       | 108/469 [00:03<00:14, 24.29it/s]\u001b[A\n","Epoch 1 in training:  24%|██▎       | 111/469 [00:03<00:14, 24.06it/s]\u001b[A\n","Epoch 1 in training:  24%|██▍       | 114/469 [00:04<00:15, 22.62it/s]\u001b[A\n","Epoch 1 in training:  25%|██▍       | 117/469 [00:04<00:16, 21.80it/s]\u001b[A\n","Epoch 1 in training:  26%|██▌       | 120/469 [00:04<00:16, 20.97it/s]\u001b[A\n","Epoch 1 in training:  26%|██▌       | 123/469 [00:04<00:16, 21.25it/s]\u001b[A\n","Epoch 1 in training:  27%|██▋       | 126/469 [00:04<00:16, 21.16it/s]\u001b[A\n","Epoch 1 in training:  28%|██▊       | 130/469 [00:04<00:13, 24.55it/s]\u001b[A\n","Epoch 1 in training:  29%|██▊       | 134/469 [00:04<00:12, 27.24it/s]\u001b[A\n","Epoch 1 in training:  29%|██▉       | 138/469 [00:04<00:11, 29.14it/s]\u001b[A\n","Epoch 1 in training:  30%|███       | 141/469 [00:05<00:11, 28.64it/s]\u001b[A\n","Epoch 1 in training:  31%|███       | 145/469 [00:05<00:10, 30.05it/s]\u001b[A\n","Epoch 1 in training:  32%|███▏      | 149/469 [00:05<00:10, 30.69it/s]\u001b[A\n","Epoch 1 in training:  33%|███▎      | 153/469 [00:05<00:09, 31.76it/s]\u001b[A\n","Epoch 1 in training:  33%|███▎      | 157/469 [00:05<00:09, 32.02it/s]\u001b[A\n","Epoch 1 in training:  34%|███▍      | 161/469 [00:05<00:09, 32.63it/s]\u001b[A\n","Epoch 1 in training:  35%|███▌      | 165/469 [00:05<00:09, 32.82it/s]\u001b[A\n","Epoch 1 in training:  36%|███▌      | 169/469 [00:05<00:09, 31.51it/s]\u001b[A\n","Epoch 1 in training:  37%|███▋      | 173/469 [00:06<00:09, 29.94it/s]\u001b[A\n","Epoch 1 in training:  38%|███▊      | 177/469 [00:06<00:09, 30.55it/s]\u001b[A\n","Epoch 1 in training:  39%|███▊      | 181/469 [00:06<00:09, 31.01it/s]\u001b[A\n","Epoch 1 in training:  39%|███▉      | 185/469 [00:06<00:09, 31.26it/s]\u001b[A\n","Epoch 1 in training:  40%|████      | 189/469 [00:06<00:08, 31.78it/s]\u001b[A\n","Epoch 1 in training:  41%|████      | 193/469 [00:06<00:08, 32.35it/s]\u001b[A\n","Epoch 1 in training:  42%|████▏     | 197/469 [00:06<00:08, 32.83it/s]\u001b[A\n","Epoch 1 in training:  43%|████▎     | 201/469 [00:06<00:08, 33.05it/s]\u001b[A\n","Epoch 1 in training:  44%|████▎     | 205/469 [00:07<00:08, 31.69it/s]\u001b[A\n","Epoch 1 in training:  45%|████▍     | 209/469 [00:07<00:08, 32.17it/s]\u001b[A\n","Epoch 1 in training:  45%|████▌     | 213/469 [00:07<00:07, 32.64it/s]\u001b[A\n","Epoch 1 in training:  46%|████▋     | 217/469 [00:07<00:07, 31.87it/s]\u001b[A\n","Epoch 1 in training:  47%|████▋     | 221/469 [00:07<00:07, 32.39it/s]\u001b[A\n","Epoch 1 in training:  48%|████▊     | 225/469 [00:07<00:07, 33.09it/s]\u001b[A\n","Epoch 1 in training:  49%|████▉     | 229/469 [00:07<00:07, 33.31it/s]\u001b[A\n","Epoch 1 in training:  50%|████▉     | 233/469 [00:07<00:07, 33.25it/s]\u001b[A\n","Epoch 1 in training:  51%|█████     | 237/469 [00:08<00:07, 31.87it/s]\u001b[A\n","Epoch 1 in training:  51%|█████▏    | 241/469 [00:08<00:07, 31.79it/s]\u001b[A\n","Epoch 1 in training:  52%|█████▏    | 245/469 [00:08<00:06, 32.52it/s]\u001b[A\n","Epoch 1 in training:  53%|█████▎    | 249/469 [00:08<00:06, 32.26it/s]\u001b[A\n","Epoch 1 in training:  54%|█████▍    | 253/469 [00:08<00:06, 32.26it/s]\u001b[A\n","Epoch 1 in training:  55%|█████▍    | 257/469 [00:08<00:06, 32.63it/s]\u001b[A\n","Epoch 1 in training:  56%|█████▌    | 261/469 [00:08<00:06, 32.78it/s]\u001b[A\n","Epoch 1 in training:  57%|█████▋    | 265/469 [00:08<00:06, 33.08it/s]\u001b[A\n","Epoch 1 in training:  57%|█████▋    | 269/469 [00:09<00:06, 32.32it/s]\u001b[A\n","Epoch 1 in training:  58%|█████▊    | 273/469 [00:09<00:06, 31.12it/s]\u001b[A\n","Epoch 1 in training:  59%|█████▉    | 277/469 [00:09<00:06, 31.58it/s]\u001b[A\n","Epoch 1 in training:  60%|█████▉    | 281/469 [00:09<00:06, 31.15it/s]\u001b[A\n","Epoch 1 in training:  61%|██████    | 285/469 [00:09<00:05, 31.45it/s]\u001b[A\n","Epoch 1 in training:  62%|██████▏   | 289/469 [00:09<00:05, 32.08it/s]\u001b[A\n","Epoch 1 in training:  62%|██████▏   | 293/469 [00:09<00:05, 32.51it/s]\u001b[A\n","Epoch 1 in training:  63%|██████▎   | 297/469 [00:09<00:05, 32.66it/s]\u001b[A\n","Epoch 1 in training:  64%|██████▍   | 301/469 [00:10<00:05, 31.67it/s]\u001b[A\n","Epoch 1 in training:  65%|██████▌   | 305/469 [00:10<00:05, 31.78it/s]\u001b[A\n","Epoch 1 in training:  66%|██████▌   | 309/469 [00:10<00:04, 32.40it/s]\u001b[A\n","Epoch 1 in training:  67%|██████▋   | 313/469 [00:10<00:04, 32.84it/s]\u001b[A\n","Epoch 1 in training:  68%|██████▊   | 317/469 [00:10<00:04, 32.30it/s]\u001b[A\n","Epoch 1 in training:  68%|██████▊   | 321/469 [00:10<00:04, 32.82it/s]\u001b[A\n","Epoch 1 in training:  69%|██████▉   | 325/469 [00:10<00:04, 32.70it/s]\u001b[A\n","Epoch 1 in training:  70%|███████   | 329/469 [00:10<00:04, 32.96it/s]\u001b[A\n","Epoch 1 in training:  71%|███████   | 333/469 [00:11<00:04, 32.27it/s]\u001b[A\n","Epoch 1 in training:  72%|███████▏  | 337/469 [00:11<00:04, 31.37it/s]\u001b[A\n","Epoch 1 in training:  73%|███████▎  | 341/469 [00:11<00:03, 32.04it/s]\u001b[A\n","Epoch 1 in training:  74%|███████▎  | 345/469 [00:11<00:03, 32.55it/s]\u001b[A\n","Epoch 1 in training:  74%|███████▍  | 349/469 [00:11<00:03, 32.15it/s]\u001b[A\n","Epoch 1 in training:  75%|███████▌  | 353/469 [00:11<00:03, 32.50it/s]\u001b[A\n","Epoch 1 in training:  76%|███████▌  | 357/469 [00:11<00:03, 32.85it/s]\u001b[A\n","Epoch 1 in training:  77%|███████▋  | 361/469 [00:11<00:03, 32.97it/s]\u001b[A\n","Epoch 1 in training:  78%|███████▊  | 365/469 [00:12<00:03, 32.03it/s]\u001b[A\n","Epoch 1 in training:  79%|███████▊  | 369/469 [00:12<00:04, 24.40it/s]\u001b[A\n","Epoch 1 in training:  79%|███████▉  | 372/469 [00:12<00:04, 23.35it/s]\u001b[A\n","Epoch 1 in training:  80%|███████▉  | 375/469 [00:12<00:03, 24.73it/s]\u001b[A\n","Epoch 1 in training:  81%|████████  | 379/469 [00:12<00:03, 26.94it/s]\u001b[A\n","Epoch 1 in training:  82%|████████▏ | 383/469 [00:12<00:03, 28.14it/s]\u001b[A\n","Epoch 1 in training:  82%|████████▏ | 386/469 [00:12<00:03, 24.26it/s]\u001b[A\n","Epoch 1 in training:  83%|████████▎ | 389/469 [00:13<00:04, 17.23it/s]\u001b[A\n","Epoch 1 in training:  84%|████████▎ | 392/469 [00:13<00:04, 18.83it/s]\u001b[A\n","Epoch 1 in training:  84%|████████▍ | 396/469 [00:13<00:03, 21.86it/s]\u001b[A\n","Epoch 1 in training:  85%|████████▌ | 399/469 [00:13<00:02, 23.47it/s]\u001b[A\n","Epoch 1 in training:  86%|████████▌ | 403/469 [00:13<00:02, 26.11it/s]\u001b[A\n","Epoch 1 in training:  87%|████████▋ | 407/469 [00:13<00:02, 28.23it/s]\u001b[A\n","Epoch 1 in training:  88%|████████▊ | 411/469 [00:13<00:01, 29.73it/s]\u001b[A\n","Epoch 1 in training:  88%|████████▊ | 415/469 [00:14<00:01, 28.97it/s]\u001b[A\n","Epoch 1 in training:  89%|████████▉ | 419/469 [00:14<00:01, 30.12it/s]\u001b[A\n","Epoch 1 in training:  90%|█████████ | 423/469 [00:14<00:01, 30.93it/s]\u001b[A\n","Epoch 1 in training:  91%|█████████ | 427/469 [00:14<00:02, 17.75it/s]\u001b[A\n","Epoch 1 in training:  92%|█████████▏| 430/469 [00:14<00:02, 18.69it/s]\u001b[A\n","Epoch 1 in training:  92%|█████████▏| 433/469 [00:15<00:01, 19.14it/s]\u001b[A\n","Epoch 1 in training:  93%|█████████▎| 436/469 [00:15<00:01, 20.07it/s]\u001b[A\n","Epoch 1 in training:  94%|█████████▎| 439/469 [00:15<00:01, 21.09it/s]\u001b[A\n","Epoch 1 in training:  94%|█████████▍| 442/469 [00:15<00:01, 22.16it/s]\u001b[A\n","Epoch 1 in training:  95%|█████████▍| 445/469 [00:15<00:01, 23.03it/s]\u001b[A\n","Epoch 1 in training:  96%|█████████▌| 448/469 [00:15<00:00, 23.21it/s]\u001b[A\n","Epoch 1 in training:  96%|█████████▌| 451/469 [00:15<00:00, 24.29it/s]\u001b[A\n","Epoch 1 in training:  97%|█████████▋| 454/469 [00:15<00:00, 24.87it/s]\u001b[A\n","Epoch 1 in training:  97%|█████████▋| 457/469 [00:16<00:00, 22.95it/s]\u001b[A\n","Epoch 1 in training:  98%|█████████▊| 460/469 [00:16<00:00, 22.57it/s]\u001b[A\n","Epoch 1 in training:  99%|█████████▊| 463/469 [00:16<00:00, 22.18it/s]\u001b[A\n","Epoch 1 in training:  99%|█████████▉| 466/469 [00:16<00:00, 22.50it/s]\u001b[A\n","Epoch 1 in training: 100%|██████████| 469/469 [00:16<00:00, 22.27it/s]\u001b[A\n","Training:  20%|██        | 1/5 [00:16<01:06, 16.62s/it]"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/5 loss: 0.81\n"]},{"output_type":"stream","name":"stderr","text":["\n","Epoch 2 in training:   0%|          | 0/469 [00:00<?, ?it/s]\u001b[A\n","Epoch 2 in training:   0%|          | 2/469 [00:00<00:25, 18.13it/s]\u001b[A\n","Epoch 2 in training:   1%|          | 5/469 [00:00<00:23, 20.14it/s]\u001b[A\n","Epoch 2 in training:   1%|▏         | 7/469 [00:00<00:23, 19.89it/s]\u001b[A\n","Epoch 2 in training:   2%|▏         | 10/469 [00:00<00:20, 22.23it/s]\u001b[A\n","Epoch 2 in training:   3%|▎         | 14/469 [00:00<00:17, 26.23it/s]\u001b[A\n","Epoch 2 in training:   4%|▍         | 18/469 [00:00<00:15, 28.78it/s]\u001b[A\n","Epoch 2 in training:   5%|▍         | 22/469 [00:00<00:14, 30.46it/s]\u001b[A\n","Epoch 2 in training:   6%|▌         | 26/469 [00:00<00:14, 30.96it/s]\u001b[A\n","Epoch 2 in training:   6%|▋         | 30/469 [00:01<00:13, 31.95it/s]\u001b[A\n","Epoch 2 in training:   7%|▋         | 34/469 [00:01<00:13, 31.71it/s]\u001b[A\n","Epoch 2 in training:   8%|▊         | 38/469 [00:01<00:13, 32.25it/s]\u001b[A\n","Epoch 2 in training:   9%|▉         | 42/469 [00:01<00:14, 30.34it/s]\u001b[A\n","Epoch 2 in training:  10%|▉         | 46/469 [00:01<00:13, 31.29it/s]\u001b[A\n","Epoch 2 in training:  11%|█         | 50/469 [00:01<00:13, 32.11it/s]\u001b[A\n","Epoch 2 in training:  12%|█▏        | 54/469 [00:01<00:12, 32.82it/s]\u001b[A\n","Epoch 2 in training:  12%|█▏        | 58/469 [00:01<00:12, 32.91it/s]\u001b[A\n","Epoch 2 in training:  13%|█▎        | 62/469 [00:02<00:12, 33.25it/s]\u001b[A\n","Epoch 2 in training:  14%|█▍        | 66/469 [00:02<00:12, 32.51it/s]\u001b[A\n","Epoch 2 in training:  15%|█▍        | 70/469 [00:02<00:12, 31.87it/s]\u001b[A\n","Epoch 2 in training:  16%|█▌        | 74/469 [00:02<00:13, 30.05it/s]\u001b[A\n","Epoch 2 in training:  17%|█▋        | 78/469 [00:02<00:12, 31.11it/s]\u001b[A\n","Epoch 2 in training:  17%|█▋        | 82/469 [00:02<00:12, 31.45it/s]\u001b[A\n","Epoch 2 in training:  18%|█▊        | 86/469 [00:02<00:11, 32.29it/s]\u001b[A\n","Epoch 2 in training:  19%|█▉        | 90/469 [00:02<00:11, 32.39it/s]\u001b[A\n","Epoch 2 in training:  20%|██        | 94/469 [00:03<00:11, 32.82it/s]\u001b[A\n","Epoch 2 in training:  21%|██        | 98/469 [00:03<00:11, 32.29it/s]\u001b[A\n","Epoch 2 in training:  22%|██▏       | 102/469 [00:03<00:11, 32.57it/s]\u001b[A\n","Epoch 2 in training:  23%|██▎       | 106/469 [00:03<00:11, 30.65it/s]\u001b[A\n","Epoch 2 in training:  23%|██▎       | 110/469 [00:03<00:11, 31.62it/s]\u001b[A\n","Epoch 2 in training:  24%|██▍       | 114/469 [00:03<00:11, 32.03it/s]\u001b[A\n","Epoch 2 in training:  25%|██▌       | 118/469 [00:03<00:11, 29.75it/s]\u001b[A\n","Epoch 2 in training:  26%|██▌       | 122/469 [00:03<00:11, 30.17it/s]\u001b[A\n","Epoch 2 in training:  27%|██▋       | 126/469 [00:04<00:11, 29.93it/s]\u001b[A\n","Epoch 2 in training:  28%|██▊       | 130/469 [00:04<00:14, 24.07it/s]\u001b[A\n","Epoch 2 in training:  28%|██▊       | 133/469 [00:04<00:13, 24.64it/s]\u001b[A\n","Epoch 2 in training:  29%|██▉       | 136/469 [00:04<00:13, 25.48it/s]\u001b[A\n","Epoch 2 in training:  30%|██▉       | 139/469 [00:04<00:14, 23.38it/s]\u001b[A\n","Epoch 2 in training:  30%|███       | 143/469 [00:04<00:12, 25.81it/s]\u001b[A\n","Epoch 2 in training:  31%|███▏      | 147/469 [00:05<00:12, 24.94it/s]\u001b[A\n","Epoch 2 in training:  32%|███▏      | 150/469 [00:05<00:13, 23.52it/s]\u001b[A\n","Epoch 2 in training:  33%|███▎      | 153/469 [00:05<00:12, 24.67it/s]\u001b[A\n","Epoch 2 in training:  33%|███▎      | 156/469 [00:05<00:12, 25.47it/s]\u001b[A\n","Epoch 2 in training:  34%|███▍      | 159/469 [00:05<00:11, 26.32it/s]\u001b[A\n","Epoch 2 in training:  35%|███▍      | 163/469 [00:05<00:10, 28.37it/s]\u001b[A\n","Epoch 2 in training:  36%|███▌      | 167/469 [00:05<00:10, 29.67it/s]\u001b[A\n","Epoch 2 in training:  36%|███▌      | 170/469 [00:05<00:10, 28.89it/s]\u001b[A\n","Epoch 2 in training:  37%|███▋      | 173/469 [00:06<00:11, 25.46it/s]\u001b[A\n","Epoch 2 in training:  38%|███▊      | 176/469 [00:06<00:11, 24.49it/s]\u001b[A\n","Epoch 2 in training:  38%|███▊      | 180/469 [00:06<00:10, 26.49it/s]\u001b[A\n","Epoch 2 in training:  39%|███▉      | 184/469 [00:06<00:10, 27.37it/s]\u001b[A\n","Epoch 2 in training:  40%|███▉      | 187/469 [00:06<00:10, 27.89it/s]\u001b[A\n","Epoch 2 in training:  41%|████      | 190/469 [00:06<00:09, 28.24it/s]\u001b[A\n","Epoch 2 in training:  41%|████▏     | 194/469 [00:06<00:09, 29.50it/s]\u001b[A\n","Epoch 2 in training:  42%|████▏     | 198/469 [00:06<00:08, 30.45it/s]\u001b[A\n","Epoch 2 in training:  43%|████▎     | 202/469 [00:06<00:08, 30.64it/s]\u001b[A\n","Epoch 2 in training:  44%|████▍     | 206/469 [00:07<00:08, 29.83it/s]\u001b[A\n","Epoch 2 in training:  45%|████▍     | 210/469 [00:07<00:08, 29.88it/s]\u001b[A\n","Epoch 2 in training:  46%|████▌     | 214/469 [00:07<00:08, 29.91it/s]\u001b[A\n","Epoch 2 in training:  46%|████▋     | 217/469 [00:07<00:09, 27.55it/s]\u001b[A\n","Epoch 2 in training:  47%|████▋     | 220/469 [00:07<00:09, 27.56it/s]\u001b[A\n","Epoch 2 in training:  48%|████▊     | 224/469 [00:07<00:08, 28.93it/s]\u001b[A\n","Epoch 2 in training:  48%|████▊     | 227/469 [00:07<00:09, 26.87it/s]\u001b[A\n","Epoch 2 in training:  49%|████▉     | 230/469 [00:08<00:09, 25.86it/s]\u001b[A\n","Epoch 2 in training:  50%|████▉     | 234/469 [00:08<00:08, 27.64it/s]\u001b[A\n","Epoch 2 in training:  51%|█████     | 238/469 [00:08<00:08, 28.30it/s]\u001b[A\n","Epoch 2 in training:  51%|█████▏    | 241/469 [00:08<00:08, 27.81it/s]\u001b[A\n","Epoch 2 in training:  52%|█████▏    | 244/469 [00:08<00:07, 28.13it/s]\u001b[A\n","Epoch 2 in training:  53%|█████▎    | 248/469 [00:08<00:07, 29.78it/s]\u001b[A\n","Epoch 2 in training:  54%|█████▎    | 251/469 [00:08<00:08, 24.62it/s]\u001b[A\n","Epoch 2 in training:  54%|█████▍    | 254/469 [00:08<00:09, 23.32it/s]\u001b[A\n","Epoch 2 in training:  55%|█████▌    | 258/469 [00:09<00:08, 26.07it/s]\u001b[A\n","Epoch 2 in training:  56%|█████▌    | 262/469 [00:09<00:07, 28.15it/s]\u001b[A\n","Epoch 2 in training:  57%|█████▋    | 266/469 [00:09<00:06, 29.75it/s]\u001b[A\n","Epoch 2 in training:  58%|█████▊    | 270/469 [00:09<00:07, 28.33it/s]\u001b[A\n","Epoch 2 in training:  58%|█████▊    | 274/469 [00:09<00:06, 29.22it/s]\u001b[A\n","Epoch 2 in training:  59%|█████▉    | 278/469 [00:09<00:06, 30.07it/s]\u001b[A\n","Epoch 2 in training:  60%|██████    | 282/469 [00:09<00:06, 30.53it/s]\u001b[A\n","Epoch 2 in training:  61%|██████    | 286/469 [00:10<00:07, 26.10it/s]\u001b[A\n","Epoch 2 in training:  62%|██████▏   | 290/469 [00:10<00:06, 27.93it/s]\u001b[A\n","Epoch 2 in training:  63%|██████▎   | 294/469 [00:10<00:05, 29.20it/s]\u001b[A\n","Epoch 2 in training:  64%|██████▎   | 298/469 [00:10<00:06, 26.63it/s]\u001b[A\n","Epoch 2 in training:  64%|██████▍   | 301/469 [00:10<00:06, 25.68it/s]\u001b[A\n","Epoch 2 in training:  65%|██████▍   | 304/469 [00:10<00:06, 25.20it/s]\u001b[A\n","Epoch 2 in training:  65%|██████▌   | 307/469 [00:10<00:06, 25.57it/s]\u001b[A\n","Epoch 2 in training:  66%|██████▌   | 310/469 [00:10<00:06, 25.48it/s]\u001b[A\n","Epoch 2 in training:  67%|██████▋   | 313/469 [00:11<00:06, 25.79it/s]\u001b[A\n","Epoch 2 in training:  67%|██████▋   | 316/469 [00:11<00:06, 25.15it/s]\u001b[A\n","Epoch 2 in training:  68%|██████▊   | 319/469 [00:11<00:05, 25.49it/s]\u001b[A\n","Epoch 2 in training:  69%|██████▊   | 322/469 [00:11<00:06, 23.88it/s]\u001b[A\n","Epoch 2 in training:  69%|██████▉   | 325/469 [00:11<00:05, 24.41it/s]\u001b[A\n","Epoch 2 in training:  70%|██████▉   | 328/469 [00:11<00:05, 24.27it/s]\u001b[A\n","Epoch 2 in training:  71%|███████   | 331/469 [00:11<00:05, 23.36it/s]\u001b[A\n","Epoch 2 in training:  71%|███████   | 334/469 [00:11<00:06, 22.49it/s]\u001b[A\n","Epoch 2 in training:  72%|███████▏  | 337/469 [00:12<00:06, 19.31it/s]\u001b[A\n","Epoch 2 in training:  72%|███████▏  | 340/469 [00:12<00:06, 19.16it/s]\u001b[A\n","Epoch 2 in training:  73%|███████▎  | 342/469 [00:12<00:06, 19.18it/s]\u001b[A\n","Epoch 2 in training:  73%|███████▎  | 344/469 [00:12<00:06, 19.12it/s]\u001b[A\n","Epoch 2 in training:  74%|███████▍  | 347/469 [00:12<00:06, 19.87it/s]\u001b[A\n","Epoch 2 in training:  75%|███████▍  | 350/469 [00:12<00:05, 20.41it/s]\u001b[A\n","Epoch 2 in training:  75%|███████▌  | 354/469 [00:12<00:04, 23.87it/s]\u001b[A\n","Epoch 2 in training:  76%|███████▋  | 358/469 [00:13<00:04, 26.46it/s]\u001b[A\n","Epoch 2 in training:  77%|███████▋  | 361/469 [00:13<00:04, 22.72it/s]\u001b[A\n","Epoch 2 in training:  78%|███████▊  | 365/469 [00:13<00:04, 24.99it/s]\u001b[A\n","Epoch 2 in training:  78%|███████▊  | 368/469 [00:13<00:04, 20.77it/s]\u001b[A\n","Epoch 2 in training:  79%|███████▉  | 371/469 [00:13<00:04, 21.52it/s]\u001b[A\n","Epoch 2 in training:  80%|███████▉  | 375/469 [00:13<00:03, 24.40it/s]\u001b[A\n","Epoch 2 in training:  81%|████████  | 379/469 [00:13<00:03, 26.81it/s]\u001b[A\n","Epoch 2 in training:  82%|████████▏ | 383/469 [00:14<00:02, 28.69it/s]\u001b[A\n","Epoch 2 in training:  83%|████████▎ | 387/469 [00:14<00:02, 30.10it/s]\u001b[A\n","Epoch 2 in training:  83%|████████▎ | 391/469 [00:14<00:02, 30.88it/s]\u001b[A\n","Epoch 2 in training:  84%|████████▍ | 395/469 [00:14<00:02, 30.00it/s]\u001b[A\n","Epoch 2 in training:  85%|████████▌ | 399/469 [00:14<00:02, 30.38it/s]\u001b[A\n","Epoch 2 in training:  86%|████████▌ | 403/469 [00:14<00:02, 31.28it/s]\u001b[A\n","Epoch 2 in training:  87%|████████▋ | 407/469 [00:14<00:01, 31.20it/s]\u001b[A\n","Epoch 2 in training:  88%|████████▊ | 411/469 [00:14<00:01, 31.48it/s]\u001b[A\n","Epoch 2 in training:  88%|████████▊ | 415/469 [00:15<00:01, 31.60it/s]\u001b[A\n","Epoch 2 in training:  89%|████████▉ | 419/469 [00:15<00:01, 32.00it/s]\u001b[A\n","Epoch 2 in training:  90%|█████████ | 423/469 [00:15<00:01, 32.41it/s]\u001b[A\n","Epoch 2 in training:  91%|█████████ | 427/469 [00:15<00:01, 30.56it/s]\u001b[A\n","Epoch 2 in training:  92%|█████████▏| 431/469 [00:15<00:01, 30.73it/s]\u001b[A\n","Epoch 2 in training:  93%|█████████▎| 435/469 [00:15<00:01, 30.93it/s]\u001b[A\n","Epoch 2 in training:  94%|█████████▎| 439/469 [00:15<00:00, 31.37it/s]\u001b[A\n","Epoch 2 in training:  94%|█████████▍| 443/469 [00:15<00:00, 31.70it/s]\u001b[A\n","Epoch 2 in training:  95%|█████████▌| 447/469 [00:16<00:00, 32.04it/s]\u001b[A\n","Epoch 2 in training:  96%|█████████▌| 451/469 [00:16<00:00, 31.66it/s]\u001b[A\n","Epoch 2 in training:  97%|█████████▋| 455/469 [00:16<00:00, 31.94it/s]\u001b[A\n","Epoch 2 in training:  98%|█████████▊| 459/469 [00:16<00:00, 30.45it/s]\u001b[A\n","Epoch 2 in training:  99%|█████████▊| 463/469 [00:16<00:00, 26.30it/s]\u001b[A\n","Epoch 2 in training: 100%|█████████▉| 467/469 [00:16<00:00, 28.17it/s]\u001b[A\n","Training:  40%|████      | 2/5 [00:33<00:50, 16.78s/it]"]},{"output_type":"stream","name":"stdout","text":["Epoch 2/5 loss: 0.47\n"]},{"output_type":"stream","name":"stderr","text":["\n","Epoch 3 in training:   0%|          | 0/469 [00:00<?, ?it/s]\u001b[A\n","Epoch 3 in training:   0%|          | 2/469 [00:00<00:31, 14.88it/s]\u001b[A\n","Epoch 3 in training:   1%|▏         | 6/469 [00:00<00:18, 24.80it/s]\u001b[A\n","Epoch 3 in training:   2%|▏         | 10/469 [00:00<00:16, 28.66it/s]\u001b[A\n","Epoch 3 in training:   3%|▎         | 14/469 [00:00<00:15, 29.11it/s]\u001b[A\n","Epoch 3 in training:   4%|▎         | 17/469 [00:00<00:15, 29.26it/s]\u001b[A\n","Epoch 3 in training:   4%|▍         | 21/469 [00:00<00:14, 30.87it/s]\u001b[A\n","Epoch 3 in training:   5%|▌         | 25/469 [00:00<00:14, 29.84it/s]\u001b[A\n","Epoch 3 in training:   6%|▌         | 29/469 [00:00<00:14, 30.74it/s]\u001b[A\n","Epoch 3 in training:   7%|▋         | 33/469 [00:01<00:13, 31.59it/s]\u001b[A\n","Epoch 3 in training:   8%|▊         | 37/469 [00:01<00:13, 32.21it/s]\u001b[A\n","Epoch 3 in training:   9%|▊         | 41/469 [00:01<00:13, 32.54it/s]\u001b[A\n","Epoch 3 in training:  10%|▉         | 45/469 [00:01<00:15, 27.64it/s]\u001b[A\n","Epoch 3 in training:  10%|█         | 48/469 [00:01<00:15, 26.81it/s]\u001b[A\n","Epoch 3 in training:  11%|█         | 52/469 [00:01<00:14, 27.90it/s]\u001b[A\n","Epoch 3 in training:  12%|█▏        | 56/469 [00:01<00:14, 29.06it/s]\u001b[A\n","Epoch 3 in training:  13%|█▎        | 60/469 [00:02<00:13, 30.18it/s]\u001b[A\n","Epoch 3 in training:  14%|█▎        | 64/469 [00:02<00:13, 31.05it/s]\u001b[A\n","Epoch 3 in training:  14%|█▍        | 68/469 [00:02<00:12, 31.59it/s]\u001b[A\n","Epoch 3 in training:  15%|█▌        | 72/469 [00:02<00:12, 31.69it/s]\u001b[A\n","Epoch 3 in training:  16%|█▌        | 76/469 [00:02<00:13, 29.47it/s]\u001b[A\n","Epoch 3 in training:  17%|█▋        | 79/469 [00:02<00:13, 28.11it/s]\u001b[A\n","Epoch 3 in training:  18%|█▊        | 83/469 [00:02<00:13, 29.45it/s]\u001b[A\n","Epoch 3 in training:  18%|█▊        | 86/469 [00:03<00:17, 21.42it/s]\u001b[A\n","Epoch 3 in training:  19%|█▉        | 89/469 [00:03<00:18, 21.08it/s]\u001b[A\n","Epoch 3 in training:  20%|█▉        | 93/469 [00:03<00:15, 24.05it/s]\u001b[A\n","Epoch 3 in training:  20%|██        | 96/469 [00:03<00:19, 19.28it/s]\u001b[A\n","Epoch 3 in training:  21%|██        | 99/469 [00:03<00:19, 19.07it/s]\u001b[A\n","Epoch 3 in training:  22%|██▏       | 103/469 [00:03<00:16, 22.26it/s]\u001b[A\n","Epoch 3 in training:  23%|██▎       | 106/469 [00:03<00:15, 23.69it/s]\u001b[A\n","Epoch 3 in training:  23%|██▎       | 110/469 [00:04<00:13, 26.06it/s]\u001b[A\n","Epoch 3 in training:  24%|██▍       | 114/469 [00:04<00:12, 28.05it/s]\u001b[A\n","Epoch 3 in training:  25%|██▌       | 118/469 [00:04<00:11, 29.66it/s]\u001b[A\n","Epoch 3 in training:  26%|██▌       | 122/469 [00:04<00:11, 30.49it/s]\u001b[A\n","Epoch 3 in training:  27%|██▋       | 126/469 [00:04<00:11, 29.96it/s]\u001b[A\n","Epoch 3 in training:  28%|██▊       | 130/469 [00:04<00:11, 30.56it/s]\u001b[A\n","Epoch 3 in training:  29%|██▊       | 134/469 [00:04<00:10, 31.21it/s]\u001b[A\n","Epoch 3 in training:  29%|██▉       | 138/469 [00:04<00:10, 31.16it/s]\u001b[A\n","Epoch 3 in training:  30%|███       | 142/469 [00:05<00:10, 31.62it/s]\u001b[A\n","Epoch 3 in training:  31%|███       | 146/469 [00:05<00:09, 32.39it/s]\u001b[A\n","Epoch 3 in training:  32%|███▏      | 150/469 [00:05<00:09, 32.34it/s]\u001b[A\n","Epoch 3 in training:  33%|███▎      | 154/469 [00:05<00:09, 32.26it/s]\u001b[A\n","Epoch 3 in training:  34%|███▎      | 158/469 [00:05<00:09, 31.13it/s]\u001b[A\n","Epoch 3 in training:  35%|███▍      | 162/469 [00:05<00:09, 31.40it/s]\u001b[A\n","Epoch 3 in training:  35%|███▌      | 166/469 [00:05<00:09, 32.01it/s]\u001b[A\n","Epoch 3 in training:  36%|███▌      | 170/469 [00:05<00:09, 30.19it/s]\u001b[A\n","Epoch 3 in training:  37%|███▋      | 174/469 [00:06<00:10, 27.49it/s]\u001b[A\n","Epoch 3 in training:  38%|███▊      | 177/469 [00:06<00:11, 26.51it/s]\u001b[A\n","Epoch 3 in training:  38%|███▊      | 180/469 [00:06<00:11, 25.82it/s]\u001b[A\n","Epoch 3 in training:  39%|███▉      | 183/469 [00:06<00:12, 23.83it/s]\u001b[A\n","Epoch 3 in training:  40%|███▉      | 186/469 [00:06<00:11, 24.15it/s]\u001b[A\n","Epoch 3 in training:  40%|████      | 189/469 [00:06<00:11, 24.19it/s]\u001b[A\n","Epoch 3 in training:  41%|████      | 192/469 [00:06<00:11, 25.15it/s]\u001b[A\n","Epoch 3 in training:  42%|████▏     | 195/469 [00:07<00:11, 24.59it/s]\u001b[A\n","Epoch 3 in training:  42%|████▏     | 198/469 [00:07<00:10, 25.08it/s]\u001b[A\n","Epoch 3 in training:  43%|████▎     | 201/469 [00:07<00:11, 24.35it/s]\u001b[A\n","Epoch 3 in training:  43%|████▎     | 204/469 [00:07<00:11, 23.23it/s]\u001b[A\n","Epoch 3 in training:  44%|████▍     | 207/469 [00:07<00:12, 21.16it/s]\u001b[A\n","Epoch 3 in training:  45%|████▍     | 210/469 [00:07<00:12, 21.47it/s]\u001b[A\n","Epoch 3 in training:  45%|████▌     | 213/469 [00:07<00:12, 21.32it/s]\u001b[A\n","Epoch 3 in training:  46%|████▌     | 216/469 [00:08<00:11, 21.15it/s]\u001b[A\n","Epoch 3 in training:  47%|████▋     | 219/469 [00:08<00:12, 20.51it/s]\u001b[A\n","Epoch 3 in training:  47%|████▋     | 222/469 [00:08<00:10, 22.61it/s]\u001b[A\n","Epoch 3 in training:  48%|████▊     | 225/469 [00:08<00:10, 24.12it/s]\u001b[A\n","Epoch 3 in training:  49%|████▊     | 228/469 [00:08<00:09, 24.86it/s]\u001b[A\n","Epoch 3 in training:  49%|████▉     | 231/469 [00:08<00:09, 26.20it/s]\u001b[A\n","Epoch 3 in training:  50%|█████     | 235/469 [00:08<00:08, 28.37it/s]\u001b[A\n","Epoch 3 in training:  51%|█████     | 239/469 [00:08<00:07, 30.08it/s]\u001b[A\n","Epoch 3 in training:  52%|█████▏    | 243/469 [00:08<00:07, 31.05it/s]\u001b[A\n","Epoch 3 in training:  53%|█████▎    | 247/469 [00:09<00:07, 30.83it/s]\u001b[A\n","Epoch 3 in training:  54%|█████▎    | 251/469 [00:09<00:06, 31.57it/s]\u001b[A\n","Epoch 3 in training:  54%|█████▍    | 255/469 [00:09<00:06, 31.97it/s]\u001b[A\n","Epoch 3 in training:  55%|█████▌    | 259/469 [00:09<00:06, 31.42it/s]\u001b[A\n","Epoch 3 in training:  56%|█████▌    | 263/469 [00:09<00:06, 29.67it/s]\u001b[A\n","Epoch 3 in training:  57%|█████▋    | 267/469 [00:09<00:06, 30.80it/s]\u001b[A\n","Epoch 3 in training:  58%|█████▊    | 271/469 [00:09<00:06, 31.28it/s]\u001b[A\n","Epoch 3 in training:  59%|█████▊    | 275/469 [00:09<00:06, 31.75it/s]\u001b[A\n","Epoch 3 in training:  59%|█████▉    | 279/469 [00:10<00:06, 31.33it/s]\u001b[A\n","Epoch 3 in training:  60%|██████    | 283/469 [00:10<00:05, 31.45it/s]\u001b[A\n","Epoch 3 in training:  61%|██████    | 287/469 [00:10<00:05, 31.86it/s]\u001b[A\n","Epoch 3 in training:  62%|██████▏   | 291/469 [00:10<00:05, 31.23it/s]\u001b[A\n","Epoch 3 in training:  63%|██████▎   | 295/469 [00:10<00:05, 31.32it/s]\u001b[A\n","Epoch 3 in training:  64%|██████▍   | 299/469 [00:10<00:05, 31.70it/s]\u001b[A\n","Epoch 3 in training:  65%|██████▍   | 303/469 [00:10<00:05, 32.02it/s]\u001b[A\n","Epoch 3 in training:  65%|██████▌   | 307/469 [00:10<00:05, 31.63it/s]\u001b[A\n","Epoch 3 in training:  66%|██████▋   | 311/469 [00:11<00:05, 31.50it/s]\u001b[A\n","Epoch 3 in training:  67%|██████▋   | 315/469 [00:11<00:04, 31.50it/s]\u001b[A\n","Epoch 3 in training:  68%|██████▊   | 319/469 [00:11<00:04, 31.61it/s]\u001b[A\n","Epoch 3 in training:  69%|██████▉   | 323/469 [00:11<00:04, 30.72it/s]\u001b[A\n","Epoch 3 in training:  70%|██████▉   | 327/469 [00:11<00:04, 31.07it/s]\u001b[A\n","Epoch 3 in training:  71%|███████   | 331/469 [00:11<00:04, 31.99it/s]\u001b[A\n","Epoch 3 in training:  71%|███████▏  | 335/469 [00:11<00:04, 32.72it/s]\u001b[A\n","Epoch 3 in training:  72%|███████▏  | 339/469 [00:11<00:03, 33.01it/s]\u001b[A\n","Epoch 3 in training:  73%|███████▎  | 343/469 [00:12<00:03, 32.80it/s]\u001b[A\n","Epoch 3 in training:  74%|███████▍  | 347/469 [00:12<00:03, 32.23it/s]\u001b[A\n","Epoch 3 in training:  75%|███████▍  | 351/469 [00:12<00:03, 32.43it/s]\u001b[A\n","Epoch 3 in training:  76%|███████▌  | 355/469 [00:12<00:03, 32.02it/s]\u001b[A\n","Epoch 3 in training:  77%|███████▋  | 359/469 [00:12<00:03, 30.97it/s]\u001b[A\n","Epoch 3 in training:  77%|███████▋  | 363/469 [00:12<00:03, 31.83it/s]\u001b[A\n","Epoch 3 in training:  78%|███████▊  | 367/469 [00:12<00:03, 32.43it/s]\u001b[A\n","Epoch 3 in training:  79%|███████▉  | 371/469 [00:12<00:02, 33.09it/s]\u001b[A\n","Epoch 3 in training:  80%|███████▉  | 375/469 [00:13<00:02, 33.25it/s]\u001b[A\n","Epoch 3 in training:  81%|████████  | 379/469 [00:13<00:02, 32.08it/s]\u001b[A\n","Epoch 3 in training:  82%|████████▏ | 383/469 [00:13<00:02, 32.53it/s]\u001b[A\n","Epoch 3 in training:  83%|████████▎ | 387/469 [00:13<00:02, 31.87it/s]\u001b[A\n","Epoch 3 in training:  83%|████████▎ | 391/469 [00:13<00:02, 31.56it/s]\u001b[A\n","Epoch 3 in training:  84%|████████▍ | 395/469 [00:13<00:02, 32.42it/s]\u001b[A\n","Epoch 3 in training:  85%|████████▌ | 399/469 [00:13<00:02, 32.57it/s]\u001b[A\n","Epoch 3 in training:  86%|████████▌ | 403/469 [00:13<00:02, 32.80it/s]\u001b[A\n","Epoch 3 in training:  87%|████████▋ | 407/469 [00:14<00:01, 33.00it/s]\u001b[A\n","Epoch 3 in training:  88%|████████▊ | 411/469 [00:14<00:01, 32.46it/s]\u001b[A\n","Epoch 3 in training:  88%|████████▊ | 415/469 [00:14<00:01, 32.96it/s]\u001b[A\n","Epoch 3 in training:  89%|████████▉ | 419/469 [00:14<00:01, 32.33it/s]\u001b[A\n","Epoch 3 in training:  90%|█████████ | 423/469 [00:14<00:01, 31.03it/s]\u001b[A\n","Epoch 3 in training:  91%|█████████ | 427/469 [00:14<00:01, 31.26it/s]\u001b[A\n","Epoch 3 in training:  92%|█████████▏| 431/469 [00:14<00:01, 31.99it/s]\u001b[A\n","Epoch 3 in training:  93%|█████████▎| 435/469 [00:14<00:01, 32.76it/s]\u001b[A\n","Epoch 3 in training:  94%|█████████▎| 439/469 [00:15<00:00, 33.09it/s]\u001b[A\n","Epoch 3 in training:  94%|█████████▍| 443/469 [00:15<00:00, 33.16it/s]\u001b[A\n","Epoch 3 in training:  95%|█████████▌| 447/469 [00:15<00:00, 32.48it/s]\u001b[A\n","Epoch 3 in training:  96%|█████████▌| 451/469 [00:15<00:00, 31.97it/s]\u001b[A\n","Epoch 3 in training:  97%|█████████▋| 455/469 [00:15<00:00, 31.01it/s]\u001b[A\n","Epoch 3 in training:  98%|█████████▊| 459/469 [00:15<00:00, 31.77it/s]\u001b[A\n","Epoch 3 in training:  99%|█████████▊| 463/469 [00:15<00:00, 32.40it/s]\u001b[A\n","Epoch 3 in training: 100%|█████████▉| 467/469 [00:15<00:00, 32.95it/s]\u001b[A\n","Training:  60%|██████    | 3/5 [00:49<00:32, 16.44s/it]"]},{"output_type":"stream","name":"stdout","text":["Epoch 3/5 loss: 0.42\n"]},{"output_type":"stream","name":"stderr","text":["\n","Epoch 4 in training:   0%|          | 0/469 [00:00<?, ?it/s]\u001b[A\n","Epoch 4 in training:   1%|          | 4/469 [00:00<00:14, 33.12it/s]\u001b[A\n","Epoch 4 in training:   2%|▏         | 8/469 [00:00<00:14, 31.67it/s]\u001b[A\n","Epoch 4 in training:   3%|▎         | 12/469 [00:00<00:14, 32.42it/s]\u001b[A\n","Epoch 4 in training:   3%|▎         | 16/469 [00:00<00:14, 30.25it/s]\u001b[A\n","Epoch 4 in training:   4%|▍         | 20/469 [00:00<00:14, 30.86it/s]\u001b[A\n","Epoch 4 in training:   5%|▌         | 24/469 [00:00<00:14, 31.61it/s]\u001b[A\n","Epoch 4 in training:   6%|▌         | 28/469 [00:00<00:13, 32.16it/s]\u001b[A\n","Epoch 4 in training:   7%|▋         | 32/469 [00:01<00:13, 32.14it/s]\u001b[A\n","Epoch 4 in training:   8%|▊         | 36/469 [00:01<00:13, 32.83it/s]\u001b[A\n","Epoch 4 in training:   9%|▊         | 40/469 [00:01<00:13, 32.89it/s]\u001b[A\n","Epoch 4 in training:   9%|▉         | 44/469 [00:01<00:12, 32.81it/s]\u001b[A\n","Epoch 4 in training:  10%|█         | 48/469 [00:01<00:13, 31.25it/s]\u001b[A\n","Epoch 4 in training:  11%|█         | 52/469 [00:01<00:12, 32.08it/s]\u001b[A\n","Epoch 4 in training:  12%|█▏        | 56/469 [00:01<00:12, 32.29it/s]\u001b[A\n","Epoch 4 in training:  13%|█▎        | 60/469 [00:01<00:12, 32.81it/s]\u001b[A\n","Epoch 4 in training:  14%|█▎        | 64/469 [00:01<00:12, 32.85it/s]\u001b[A\n","Epoch 4 in training:  14%|█▍        | 68/469 [00:02<00:12, 33.09it/s]\u001b[A\n","Epoch 4 in training:  15%|█▌        | 72/469 [00:02<00:13, 30.52it/s]\u001b[A\n","Epoch 4 in training:  16%|█▌        | 76/469 [00:02<00:14, 27.16it/s]\u001b[A\n","Epoch 4 in training:  17%|█▋        | 79/469 [00:02<00:15, 25.73it/s]\u001b[A\n","Epoch 4 in training:  17%|█▋        | 82/469 [00:02<00:15, 25.63it/s]\u001b[A\n","Epoch 4 in training:  18%|█▊        | 85/469 [00:02<00:14, 25.61it/s]\u001b[A\n","Epoch 4 in training:  19%|█▉        | 88/469 [00:02<00:14, 25.84it/s]\u001b[A\n","Epoch 4 in training:  19%|█▉        | 91/469 [00:03<00:14, 25.68it/s]\u001b[A\n","Epoch 4 in training:  20%|██        | 94/469 [00:03<00:14, 25.88it/s]\u001b[A\n","Epoch 4 in training:  21%|██        | 97/469 [00:03<00:14, 26.33it/s]\u001b[A\n","Epoch 4 in training:  21%|██▏       | 100/469 [00:03<00:14, 25.73it/s]\u001b[A\n","Epoch 4 in training:  22%|██▏       | 103/469 [00:03<00:15, 23.80it/s]\u001b[A\n","Epoch 4 in training:  23%|██▎       | 106/469 [00:03<00:15, 23.02it/s]\u001b[A\n","Epoch 4 in training:  23%|██▎       | 109/469 [00:03<00:15, 22.85it/s]\u001b[A\n","Epoch 4 in training:  24%|██▍       | 112/469 [00:03<00:15, 22.42it/s]\u001b[A\n","Epoch 4 in training:  25%|██▍       | 115/469 [00:04<00:16, 21.88it/s]\u001b[A\n","Epoch 4 in training:  25%|██▌       | 118/469 [00:04<00:15, 22.21it/s]\u001b[A\n","Epoch 4 in training:  26%|██▌       | 121/469 [00:04<00:15, 21.79it/s]\u001b[A\n","Epoch 4 in training:  26%|██▋       | 124/469 [00:04<00:15, 21.59it/s]\u001b[A\n","Epoch 4 in training:  27%|██▋       | 128/469 [00:04<00:13, 24.81it/s]\u001b[A\n","Epoch 4 in training:  28%|██▊       | 132/469 [00:04<00:12, 27.36it/s]\u001b[A\n","Epoch 4 in training:  29%|██▉       | 136/469 [00:04<00:11, 29.36it/s]\u001b[A\n","Epoch 4 in training:  30%|██▉       | 140/469 [00:04<00:10, 30.58it/s]\u001b[A\n","Epoch 4 in training:  31%|███       | 144/469 [00:05<00:10, 30.42it/s]\u001b[A\n","Epoch 4 in training:  32%|███▏      | 148/469 [00:05<00:10, 31.45it/s]\u001b[A\n","Epoch 4 in training:  32%|███▏      | 152/469 [00:05<00:09, 32.08it/s]\u001b[A\n","Epoch 4 in training:  33%|███▎      | 156/469 [00:05<00:10, 30.16it/s]\u001b[A\n","Epoch 4 in training:  34%|███▍      | 160/469 [00:05<00:10, 30.51it/s]\u001b[A\n","Epoch 4 in training:  35%|███▍      | 164/469 [00:05<00:09, 31.47it/s]\u001b[A\n","Epoch 4 in training:  36%|███▌      | 168/469 [00:05<00:09, 32.27it/s]\u001b[A\n","Epoch 4 in training:  37%|███▋      | 172/469 [00:05<00:09, 32.53it/s]\u001b[A\n","Epoch 4 in training:  38%|███▊      | 176/469 [00:06<00:08, 33.13it/s]\u001b[A\n","Epoch 4 in training:  38%|███▊      | 180/469 [00:06<00:08, 33.48it/s]\u001b[A\n","Epoch 4 in training:  39%|███▉      | 184/469 [00:06<00:08, 33.86it/s]\u001b[A\n","Epoch 4 in training:  40%|████      | 188/469 [00:06<00:08, 32.09it/s]\u001b[A\n","Epoch 4 in training:  41%|████      | 192/469 [00:06<00:08, 31.28it/s]\u001b[A\n","Epoch 4 in training:  42%|████▏     | 196/469 [00:06<00:08, 32.11it/s]\u001b[A\n","Epoch 4 in training:  43%|████▎     | 200/469 [00:06<00:08, 32.41it/s]\u001b[A\n","Epoch 4 in training:  43%|████▎     | 204/469 [00:06<00:08, 32.87it/s]\u001b[A\n","Epoch 4 in training:  44%|████▍     | 208/469 [00:07<00:07, 33.33it/s]\u001b[A\n","Epoch 4 in training:  45%|████▌     | 212/469 [00:07<00:07, 33.39it/s]\u001b[A\n","Epoch 4 in training:  46%|████▌     | 216/469 [00:07<00:07, 33.72it/s]\u001b[A\n","Epoch 4 in training:  47%|████▋     | 220/469 [00:07<00:07, 32.64it/s]\u001b[A\n","Epoch 4 in training:  48%|████▊     | 224/469 [00:07<00:07, 31.38it/s]\u001b[A\n","Epoch 4 in training:  49%|████▊     | 228/469 [00:07<00:07, 31.97it/s]\u001b[A\n","Epoch 4 in training:  49%|████▉     | 232/469 [00:07<00:07, 32.52it/s]\u001b[A\n","Epoch 4 in training:  50%|█████     | 236/469 [00:07<00:07, 33.12it/s]\u001b[A\n","Epoch 4 in training:  51%|█████     | 240/469 [00:08<00:06, 33.27it/s]\u001b[A\n","Epoch 4 in training:  52%|█████▏    | 244/469 [00:08<00:06, 33.47it/s]\u001b[A\n","Epoch 4 in training:  53%|█████▎    | 248/469 [00:08<00:06, 33.49it/s]\u001b[A\n","Epoch 4 in training:  54%|█████▎    | 252/469 [00:08<00:06, 33.34it/s]\u001b[A\n","Epoch 4 in training:  55%|█████▍    | 256/469 [00:08<00:06, 31.11it/s]\u001b[A\n","Epoch 4 in training:  55%|█████▌    | 260/469 [00:08<00:06, 31.87it/s]\u001b[A\n","Epoch 4 in training:  56%|█████▋    | 264/469 [00:08<00:06, 32.38it/s]\u001b[A\n","Epoch 4 in training:  57%|█████▋    | 268/469 [00:08<00:06, 32.59it/s]\u001b[A\n","Epoch 4 in training:  58%|█████▊    | 272/469 [00:09<00:05, 32.96it/s]\u001b[A\n","Epoch 4 in training:  59%|█████▉    | 276/469 [00:09<00:05, 33.09it/s]\u001b[A\n","Epoch 4 in training:  60%|█████▉    | 280/469 [00:09<00:05, 33.21it/s]\u001b[A\n","Epoch 4 in training:  61%|██████    | 284/469 [00:09<00:05, 33.22it/s]\u001b[A\n","Epoch 4 in training:  61%|██████▏   | 288/469 [00:09<00:06, 29.93it/s]\u001b[A\n","Epoch 4 in training:  62%|██████▏   | 292/469 [00:09<00:05, 31.03it/s]\u001b[A\n","Epoch 4 in training:  63%|██████▎   | 296/469 [00:09<00:05, 31.78it/s]\u001b[A\n","Epoch 4 in training:  64%|██████▍   | 300/469 [00:09<00:05, 32.48it/s]\u001b[A\n","Epoch 4 in training:  65%|██████▍   | 304/469 [00:10<00:05, 32.76it/s]\u001b[A\n","Epoch 4 in training:  66%|██████▌   | 308/469 [00:10<00:04, 32.78it/s]\u001b[A\n","Epoch 4 in training:  67%|██████▋   | 312/469 [00:10<00:04, 33.20it/s]\u001b[A\n","Epoch 4 in training:  67%|██████▋   | 316/469 [00:10<00:04, 33.39it/s]\u001b[A\n","Epoch 4 in training:  68%|██████▊   | 320/469 [00:10<00:04, 31.57it/s]\u001b[A\n","Epoch 4 in training:  69%|██████▉   | 324/469 [00:10<00:04, 31.74it/s]\u001b[A\n","Epoch 4 in training:  70%|██████▉   | 328/469 [00:10<00:04, 32.41it/s]\u001b[A\n","Epoch 4 in training:  71%|███████   | 332/469 [00:10<00:04, 32.84it/s]\u001b[A\n","Epoch 4 in training:  72%|███████▏  | 336/469 [00:11<00:03, 33.29it/s]\u001b[A\n","Epoch 4 in training:  72%|███████▏  | 340/469 [00:11<00:03, 33.48it/s]\u001b[A\n","Epoch 4 in training:  73%|███████▎  | 344/469 [00:11<00:03, 33.76it/s]\u001b[A\n","Epoch 4 in training:  74%|███████▍  | 348/469 [00:11<00:03, 33.54it/s]\u001b[A\n","Epoch 4 in training:  75%|███████▌  | 352/469 [00:11<00:03, 31.58it/s]\u001b[A\n","Epoch 4 in training:  76%|███████▌  | 356/469 [00:11<00:03, 31.48it/s]\u001b[A\n","Epoch 4 in training:  77%|███████▋  | 360/469 [00:11<00:03, 32.23it/s]\u001b[A\n","Epoch 4 in training:  78%|███████▊  | 364/469 [00:11<00:03, 32.89it/s]\u001b[A\n","Epoch 4 in training:  78%|███████▊  | 368/469 [00:11<00:03, 33.25it/s]\u001b[A\n","Epoch 4 in training:  79%|███████▉  | 372/469 [00:12<00:02, 33.23it/s]\u001b[A\n","Epoch 4 in training:  80%|████████  | 376/469 [00:12<00:02, 33.46it/s]\u001b[A\n","Epoch 4 in training:  81%|████████  | 380/469 [00:12<00:02, 33.71it/s]\u001b[A\n","Epoch 4 in training:  82%|████████▏ | 384/469 [00:12<00:02, 31.92it/s]\u001b[A\n","Epoch 4 in training:  83%|████████▎ | 388/469 [00:12<00:02, 31.55it/s]\u001b[A\n","Epoch 4 in training:  84%|████████▎ | 392/469 [00:12<00:02, 31.57it/s]\u001b[A\n","Epoch 4 in training:  84%|████████▍ | 396/469 [00:12<00:02, 32.13it/s]\u001b[A\n","Epoch 4 in training:  85%|████████▌ | 400/469 [00:12<00:02, 32.64it/s]\u001b[A\n","Epoch 4 in training:  86%|████████▌ | 404/469 [00:13<00:01, 32.94it/s]\u001b[A\n","Epoch 4 in training:  87%|████████▋ | 408/469 [00:13<00:01, 33.12it/s]\u001b[A\n","Epoch 4 in training:  88%|████████▊ | 412/469 [00:13<00:01, 33.44it/s]\u001b[A\n","Epoch 4 in training:  89%|████████▊ | 416/469 [00:13<00:01, 31.48it/s]\u001b[A\n","Epoch 4 in training:  90%|████████▉ | 420/469 [00:13<00:01, 31.69it/s]\u001b[A\n","Epoch 4 in training:  90%|█████████ | 424/469 [00:13<00:01, 31.16it/s]\u001b[A\n","Epoch 4 in training:  91%|█████████▏| 428/469 [00:13<00:01, 31.98it/s]\u001b[A\n","Epoch 4 in training:  92%|█████████▏| 432/469 [00:13<00:01, 32.30it/s]\u001b[A\n","Epoch 4 in training:  93%|█████████▎| 436/469 [00:14<00:01, 32.85it/s]\u001b[A\n","Epoch 4 in training:  94%|█████████▍| 440/469 [00:14<00:00, 32.71it/s]\u001b[A\n","Epoch 4 in training:  95%|█████████▍| 444/469 [00:14<00:00, 33.07it/s]\u001b[A\n","Epoch 4 in training:  96%|█████████▌| 448/469 [00:14<00:00, 31.79it/s]\u001b[A\n","Epoch 4 in training:  96%|█████████▋| 452/469 [00:14<00:00, 28.21it/s]\u001b[A\n","Epoch 4 in training:  97%|█████████▋| 455/469 [00:14<00:00, 26.56it/s]\u001b[A\n","Epoch 4 in training:  98%|█████████▊| 458/469 [00:14<00:00, 26.35it/s]\u001b[A\n","Epoch 4 in training:  98%|█████████▊| 461/469 [00:15<00:00, 25.85it/s]\u001b[A\n","Epoch 4 in training:  99%|█████████▉| 464/469 [00:15<00:00, 25.95it/s]\u001b[A\n","Epoch 4 in training: 100%|█████████▉| 467/469 [00:15<00:00, 25.88it/s]\u001b[A\n","Training:  80%|████████  | 4/5 [01:04<00:16, 16.01s/it]"]},{"output_type":"stream","name":"stdout","text":["Epoch 4/5 loss: 0.39\n"]},{"output_type":"stream","name":"stderr","text":["\n","Epoch 5 in training:   0%|          | 0/469 [00:00<?, ?it/s]\u001b[A\n","Epoch 5 in training:   1%|          | 3/469 [00:00<00:21, 21.42it/s]\u001b[A\n","Epoch 5 in training:   1%|▏         | 6/469 [00:00<00:22, 20.80it/s]\u001b[A\n","Epoch 5 in training:   2%|▏         | 9/469 [00:00<00:21, 21.42it/s]\u001b[A\n","Epoch 5 in training:   3%|▎         | 12/469 [00:00<00:20, 22.56it/s]\u001b[A\n","Epoch 5 in training:   3%|▎         | 15/469 [00:00<00:20, 22.10it/s]\u001b[A\n","Epoch 5 in training:   4%|▍         | 18/469 [00:00<00:19, 23.21it/s]\u001b[A\n","Epoch 5 in training:   4%|▍         | 21/469 [00:00<00:19, 22.50it/s]\u001b[A\n","Epoch 5 in training:   5%|▌         | 24/469 [00:01<00:20, 22.12it/s]\u001b[A\n","Epoch 5 in training:   6%|▌         | 27/469 [00:01<00:20, 21.50it/s]\u001b[A\n","Epoch 5 in training:   6%|▋         | 30/469 [00:01<00:20, 21.89it/s]\u001b[A\n","Epoch 5 in training:   7%|▋         | 33/469 [00:01<00:20, 20.92it/s]\u001b[A\n","Epoch 5 in training:   8%|▊         | 36/469 [00:01<00:20, 21.34it/s]\u001b[A\n","Epoch 5 in training:   9%|▊         | 40/469 [00:01<00:17, 24.81it/s]\u001b[A\n","Epoch 5 in training:   9%|▉         | 44/469 [00:01<00:15, 27.47it/s]\u001b[A\n","Epoch 5 in training:  10%|█         | 48/469 [00:02<00:14, 29.53it/s]\u001b[A\n","Epoch 5 in training:  11%|█         | 52/469 [00:02<00:14, 29.40it/s]\u001b[A\n","Epoch 5 in training:  12%|█▏        | 56/469 [00:02<00:13, 30.46it/s]\u001b[A\n","Epoch 5 in training:  13%|█▎        | 60/469 [00:02<00:12, 31.58it/s]\u001b[A\n","Epoch 5 in training:  14%|█▎        | 64/469 [00:02<00:12, 31.78it/s]\u001b[A\n","Epoch 5 in training:  14%|█▍        | 68/469 [00:02<00:12, 32.53it/s]\u001b[A\n","Epoch 5 in training:  15%|█▌        | 72/469 [00:02<00:12, 32.85it/s]\u001b[A\n","Epoch 5 in training:  16%|█▌        | 76/469 [00:02<00:11, 33.12it/s]\u001b[A\n","Epoch 5 in training:  17%|█▋        | 80/469 [00:02<00:11, 33.55it/s]\u001b[A\n","Epoch 5 in training:  18%|█▊        | 84/469 [00:03<00:11, 32.63it/s]\u001b[A\n","Epoch 5 in training:  19%|█▉        | 88/469 [00:03<00:11, 31.96it/s]\u001b[A\n","Epoch 5 in training:  20%|█▉        | 92/469 [00:03<00:11, 32.25it/s]\u001b[A\n","Epoch 5 in training:  20%|██        | 96/469 [00:03<00:11, 32.12it/s]\u001b[A\n","Epoch 5 in training:  21%|██▏       | 100/469 [00:03<00:11, 32.87it/s]\u001b[A\n","Epoch 5 in training:  22%|██▏       | 104/469 [00:03<00:11, 33.16it/s]\u001b[A\n","Epoch 5 in training:  23%|██▎       | 108/469 [00:03<00:10, 33.19it/s]\u001b[A\n","Epoch 5 in training:  24%|██▍       | 112/469 [00:03<00:10, 33.47it/s]\u001b[A\n","Epoch 5 in training:  25%|██▍       | 116/469 [00:04<00:10, 33.30it/s]\u001b[A\n","Epoch 5 in training:  26%|██▌       | 120/469 [00:04<00:11, 31.69it/s]\u001b[A\n","Epoch 5 in training:  26%|██▋       | 124/469 [00:04<00:10, 31.59it/s]\u001b[A\n","Epoch 5 in training:  27%|██▋       | 128/469 [00:04<00:10, 32.16it/s]\u001b[A\n","Epoch 5 in training:  28%|██▊       | 132/469 [00:04<00:10, 31.90it/s]\u001b[A\n","Epoch 5 in training:  29%|██▉       | 136/469 [00:04<00:10, 32.45it/s]\u001b[A\n","Epoch 5 in training:  30%|██▉       | 140/469 [00:04<00:10, 32.77it/s]\u001b[A\n","Epoch 5 in training:  31%|███       | 144/469 [00:04<00:09, 32.58it/s]\u001b[A\n","Epoch 5 in training:  32%|███▏      | 148/469 [00:05<00:09, 32.66it/s]\u001b[A\n","Epoch 5 in training:  32%|███▏      | 152/469 [00:05<00:10, 31.57it/s]\u001b[A\n","Epoch 5 in training:  33%|███▎      | 156/469 [00:05<00:09, 31.95it/s]\u001b[A\n","Epoch 5 in training:  34%|███▍      | 160/469 [00:05<00:09, 32.19it/s]\u001b[A\n","Epoch 5 in training:  35%|███▍      | 164/469 [00:05<00:09, 31.23it/s]\u001b[A\n","Epoch 5 in training:  36%|███▌      | 168/469 [00:05<00:09, 31.64it/s]\u001b[A\n","Epoch 5 in training:  37%|███▋      | 172/469 [00:05<00:09, 32.17it/s]\u001b[A\n","Epoch 5 in training:  38%|███▊      | 176/469 [00:05<00:08, 32.57it/s]\u001b[A\n","Epoch 5 in training:  38%|███▊      | 180/469 [00:06<00:08, 32.17it/s]\u001b[A\n","Epoch 5 in training:  39%|███▉      | 184/469 [00:06<00:09, 31.01it/s]\u001b[A\n","Epoch 5 in training:  40%|████      | 188/469 [00:06<00:08, 31.74it/s]\u001b[A\n","Epoch 5 in training:  41%|████      | 192/469 [00:06<00:08, 32.40it/s]\u001b[A\n","Epoch 5 in training:  42%|████▏     | 196/469 [00:06<00:08, 32.47it/s]\u001b[A\n","Epoch 5 in training:  43%|████▎     | 200/469 [00:06<00:08, 32.64it/s]\u001b[A\n","Epoch 5 in training:  43%|████▎     | 204/469 [00:06<00:08, 32.98it/s]\u001b[A\n","Epoch 5 in training:  44%|████▍     | 208/469 [00:06<00:07, 33.40it/s]\u001b[A\n","Epoch 5 in training:  45%|████▌     | 212/469 [00:07<00:07, 33.68it/s]\u001b[A\n","Epoch 5 in training:  46%|████▌     | 216/469 [00:07<00:08, 31.62it/s]\u001b[A\n","Epoch 5 in training:  47%|████▋     | 220/469 [00:07<00:07, 32.14it/s]\u001b[A\n","Epoch 5 in training:  48%|████▊     | 224/469 [00:07<00:07, 32.68it/s]\u001b[A\n","Epoch 5 in training:  49%|████▊     | 228/469 [00:07<00:07, 33.25it/s]\u001b[A\n","Epoch 5 in training:  49%|████▉     | 232/469 [00:07<00:07, 32.54it/s]\u001b[A\n","Epoch 5 in training:  50%|█████     | 236/469 [00:07<00:07, 33.06it/s]\u001b[A\n","Epoch 5 in training:  51%|█████     | 240/469 [00:07<00:06, 33.39it/s]\u001b[A\n","Epoch 5 in training:  52%|█████▏    | 244/469 [00:08<00:06, 33.74it/s]\u001b[A\n","Epoch 5 in training:  53%|█████▎    | 248/469 [00:08<00:06, 32.02it/s]\u001b[A\n","Epoch 5 in training:  54%|█████▎    | 252/469 [00:08<00:06, 32.62it/s]\u001b[A\n","Epoch 5 in training:  55%|█████▍    | 256/469 [00:08<00:06, 33.07it/s]\u001b[A\n","Epoch 5 in training:  55%|█████▌    | 260/469 [00:08<00:06, 33.64it/s]\u001b[A\n","Epoch 5 in training:  56%|█████▋    | 264/469 [00:08<00:06, 32.97it/s]\u001b[A\n","Epoch 5 in training:  57%|█████▋    | 268/469 [00:08<00:05, 33.56it/s]\u001b[A\n","Epoch 5 in training:  58%|█████▊    | 272/469 [00:08<00:05, 33.69it/s]\u001b[A\n","Epoch 5 in training:  59%|█████▉    | 276/469 [00:08<00:05, 33.97it/s]\u001b[A\n","Epoch 5 in training:  60%|█████▉    | 280/469 [00:09<00:05, 32.31it/s]\u001b[A\n","Epoch 5 in training:  61%|██████    | 284/469 [00:09<00:05, 31.26it/s]\u001b[A\n","Epoch 5 in training:  61%|██████▏   | 288/469 [00:09<00:05, 31.95it/s]\u001b[A\n","Epoch 5 in training:  62%|██████▏   | 292/469 [00:09<00:05, 32.56it/s]\u001b[A\n","Epoch 5 in training:  63%|██████▎   | 296/469 [00:09<00:05, 32.49it/s]\u001b[A\n","Epoch 5 in training:  64%|██████▍   | 300/469 [00:09<00:05, 32.55it/s]\u001b[A\n","Epoch 5 in training:  65%|██████▍   | 304/469 [00:09<00:05, 32.97it/s]\u001b[A\n","Epoch 5 in training:  66%|██████▌   | 308/469 [00:09<00:04, 33.24it/s]\u001b[A\n","Epoch 5 in training:  67%|██████▋   | 312/469 [00:10<00:04, 32.34it/s]\u001b[A\n","Epoch 5 in training:  67%|██████▋   | 316/469 [00:10<00:04, 30.66it/s]\u001b[A\n","Epoch 5 in training:  68%|██████▊   | 320/469 [00:10<00:04, 31.51it/s]\u001b[A\n","Epoch 5 in training:  69%|██████▉   | 324/469 [00:10<00:04, 32.27it/s]\u001b[A\n","Epoch 5 in training:  70%|██████▉   | 328/469 [00:10<00:04, 32.63it/s]\u001b[A\n","Epoch 5 in training:  71%|███████   | 332/469 [00:10<00:04, 32.36it/s]\u001b[A\n","Epoch 5 in training:  72%|███████▏  | 336/469 [00:10<00:04, 32.73it/s]\u001b[A\n","Epoch 5 in training:  72%|███████▏  | 340/469 [00:10<00:03, 33.18it/s]\u001b[A\n","Epoch 5 in training:  73%|███████▎  | 344/469 [00:11<00:03, 32.56it/s]\u001b[A\n","Epoch 5 in training:  74%|███████▍  | 348/469 [00:11<00:03, 31.96it/s]\u001b[A\n","Epoch 5 in training:  75%|███████▌  | 352/469 [00:11<00:03, 32.33it/s]\u001b[A\n","Epoch 5 in training:  76%|███████▌  | 356/469 [00:11<00:03, 32.51it/s]\u001b[A\n","Epoch 5 in training:  77%|███████▋  | 360/469 [00:11<00:03, 32.89it/s]\u001b[A\n","Epoch 5 in training:  78%|███████▊  | 364/469 [00:11<00:03, 27.99it/s]\u001b[A\n","Epoch 5 in training:  78%|███████▊  | 367/469 [00:11<00:03, 26.77it/s]\u001b[A\n","Epoch 5 in training:  79%|███████▉  | 370/469 [00:12<00:03, 26.20it/s]\u001b[A\n","Epoch 5 in training:  80%|███████▉  | 373/469 [00:12<00:03, 24.49it/s]\u001b[A\n","Epoch 5 in training:  80%|████████  | 376/469 [00:12<00:03, 24.63it/s]\u001b[A\n","Epoch 5 in training:  81%|████████  | 379/469 [00:12<00:03, 24.54it/s]\u001b[A\n","Epoch 5 in training:  81%|████████▏ | 382/469 [00:12<00:03, 25.20it/s]\u001b[A\n","Epoch 5 in training:  82%|████████▏ | 385/469 [00:12<00:03, 25.64it/s]\u001b[A\n","Epoch 5 in training:  83%|████████▎ | 388/469 [00:12<00:03, 24.78it/s]\u001b[A\n","Epoch 5 in training:  83%|████████▎ | 391/469 [00:12<00:03, 24.96it/s]\u001b[A\n","Epoch 5 in training:  84%|████████▍ | 394/469 [00:13<00:03, 24.48it/s]\u001b[A\n","Epoch 5 in training:  85%|████████▍ | 397/469 [00:13<00:03, 23.12it/s]\u001b[A\n","Epoch 5 in training:  85%|████████▌ | 400/469 [00:13<00:03, 22.14it/s]\u001b[A\n","Epoch 5 in training:  86%|████████▌ | 403/469 [00:13<00:02, 22.15it/s]\u001b[A\n","Epoch 5 in training:  87%|████████▋ | 406/469 [00:13<00:02, 22.10it/s]\u001b[A\n","Epoch 5 in training:  87%|████████▋ | 409/469 [00:13<00:02, 21.96it/s]\u001b[A\n","Epoch 5 in training:  88%|████████▊ | 412/469 [00:13<00:02, 21.46it/s]\u001b[A\n","Epoch 5 in training:  88%|████████▊ | 415/469 [00:13<00:02, 23.20it/s]\u001b[A\n","Epoch 5 in training:  89%|████████▉ | 418/469 [00:14<00:02, 24.89it/s]\u001b[A\n","Epoch 5 in training:  90%|████████▉ | 421/469 [00:14<00:01, 25.70it/s]\u001b[A\n","Epoch 5 in training:  91%|█████████ | 425/469 [00:14<00:01, 28.05it/s]\u001b[A\n","Epoch 5 in training:  91%|█████████▏| 429/469 [00:14<00:01, 29.76it/s]\u001b[A\n","Epoch 5 in training:  92%|█████████▏| 433/469 [00:14<00:01, 31.06it/s]\u001b[A\n","Epoch 5 in training:  93%|█████████▎| 437/469 [00:14<00:01, 31.82it/s]\u001b[A\n","Epoch 5 in training:  94%|█████████▍| 441/469 [00:14<00:00, 32.46it/s]\u001b[A\n","Epoch 5 in training:  95%|█████████▍| 445/469 [00:14<00:00, 32.14it/s]\u001b[A\n","Epoch 5 in training:  96%|█████████▌| 449/469 [00:15<00:00, 32.67it/s]\u001b[A\n","Epoch 5 in training:  97%|█████████▋| 453/469 [00:15<00:00, 30.92it/s]\u001b[A\n","Epoch 5 in training:  97%|█████████▋| 457/469 [00:15<00:00, 31.79it/s]\u001b[A\n","Epoch 5 in training:  98%|█████████▊| 461/469 [00:15<00:00, 32.18it/s]\u001b[A\n","Epoch 5 in training:  99%|█████████▉| 465/469 [00:15<00:00, 32.80it/s]\u001b[A\n","Epoch 5 in training: 100%|██████████| 469/469 [00:15<00:00, 33.08it/s]\u001b[A\n","Training: 100%|██████████| 5/5 [01:20<00:00, 16.12s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 5/5 loss: 0.37\n"]},{"output_type":"stream","name":"stderr","text":["Testing: 100%|██████████| 79/79 [00:01<00:00, 48.55it/s]"]},{"output_type":"stream","name":"stdout","text":["Test loss: 0.40\n","Test accuracy: 85.18%\n","Saved Trained Model.\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}],"source":["def Train():\n","    ##############################################################################\n","    #                           IMPLEMENT YOUR CODE                              #\n","    ##############################################################################\n","\n","    patch_size=4\n","    embed_dim=32\n","    depth=6\n","    num_heads=16\n","    mlp_ratio=4\n","\n","\n","\n","\n","# 85.3\n","    # patch_size=7\n","    # embed_dim=32\n","    # depth=6\n","    # num_heads=4 # make sure embed_dim is divisible by num_heads!\n","    # mlp_ratio=4\n","\n","\n","    # patch_size=7\n","    # embed_dim=32\n","    # depth=6\n","    # num_heads=16 # make sure embed_dim is divisible by num_heads!\n","    # mlp_ratio=4\n","\n","\n","    # patch_size=7\n","    # embed_dim=16\n","    # depth=6\n","    # num_heads=4 # make sure embed_dim is divisible by num_heads!\n","    # mlp_ratio=4\n","\n","    ##############################################################################\n","    #                              END YOUR CODE                                 #\n","    ##############################################################################\n","\n","    # Loading data\n","    transform = ToTensor()\n","\n","    train_set = FashionMNIST(root='./data', train=True, download=True, transform=transform)\n","    test_set = FashionMNIST(root='./data', train=False, download=True, transform=transform)\n","\n","    train_loader = DataLoader(train_set, shuffle=True, batch_size=128)\n","    test_loader = DataLoader(test_set, shuffle=False, batch_size=128)\n","\n","    # Defining model and training options\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","    print(\"Using device: \", device, f\"({torch.cuda.get_device_name(device)})\" if torch.cuda.is_available() else \"\")\n","\n","    model = VisionTransformer(patch_size=patch_size, embed_dim=embed_dim, depth=depth, num_heads=num_heads, mlp_ratio=mlp_ratio).to(device)\n","    model_path = './vit.pth'\n","    N_EPOCHS = 5\n","    LR = 0.005\n","\n","    # Training loop\n","    optimizer = Adam(model.parameters(), lr=LR)\n","    criterion = CrossEntropyLoss()\n","    for epoch in trange(N_EPOCHS, desc=\"Training\"):\n","        train_loss = 0.0\n","        for batch in tqdm(train_loader, desc=f\"Epoch {epoch + 1} in training\", leave=False):\n","            x, y = batch\n","            x, y = x.to(device), y.to(device)\n","            y_hat = model(x)\n","            loss = criterion(y_hat, y)\n","\n","            train_loss += loss.detach().cpu().item() / len(train_loader)\n","\n","            optimizer.zero_grad()\n","            loss.backward()\n","            optimizer.step()\n","\n","        print(f\"Epoch {epoch + 1}/{N_EPOCHS} loss: {train_loss:.2f}\")\n","\n","    # Test loop\n","    with torch.no_grad():\n","        correct, total = 0, 0\n","        test_loss = 0.0\n","        for batch in tqdm(test_loader, desc=\"Testing\"):\n","            x, y = batch\n","            x, y = x.to(device), y.to(device)\n","            y_hat = model(x)\n","            loss = criterion(y_hat, y)\n","            test_loss += loss.detach().cpu().item() / len(test_loader)\n","\n","            correct += torch.sum(torch.argmax(y_hat, dim=1) == y).detach().cpu().item()\n","            total += len(x)\n","        print(f\"Test loss: {test_loss:.2f}\")\n","        print(f\"Test accuracy: {correct / total * 100:.2f}%\")\n","\n","    torch.save(model.state_dict(), model_path)\n","    print('Saved Trained Model.')\n","\n","Train()"]},{"cell_type":"markdown","metadata":{"id":"EFZFGvpPUXZ6"},"source":["### Describe what you did and discovered here\n","In this cell you should write all the settings tried and performances you obtained. Report what you did and what you discovered from the trials.\n","You can write in Korean and English"]},{"cell_type":"markdown","metadata":{"id":"GVagY_JcUXZ6"},"source":["    patch_size=4\n","    embed_dim=32\n","    depth=6\n","    num_heads=8\n","    mlp_ratio=4\n","Test accuracy: 84.32%\n","\n","    patch_size=4\n","    embed_dim=16\n","    depth=6\n","    num_heads=8\n","    mlp_ratio=4\n","Test accuracy: 83.90% -> embed_dim을 줄였을 때 정확도가 감소하였다.\n","\n","    patch_size=4\n","    embed_dim=16\n","    depth=6\n","    num_heads=4\n","    mlp_ratio=4\n","Test accuracy: 83.41% -> num_heads를 줄였을 때 정확도가 감소하였다. 모델의 표현력이 줄어 정확도가 줄어든 것으로 보인다.\n","\n","    patch_size=4\n","    embed_dim=32\n","    depth=6\n","    num_heads=16\n","    mlp_ratio=4\n","Test accuracy: 85.18% -> num_heads를 증가시켰더니 정확도 증가했다. 패치에 대해 더 많은 정보를 가질 수 있어, 모델의 표현력이 증가해 성능이 향상된 것으로 보인다."]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.17"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}